name: Automated Quality Monitoring

on:
  schedule:
    # Run daily at 6 AM UTC (2 AM EST / 11 PM PST)
    - cron: '0 6 * * *'
  workflow_dispatch:
    inputs:
      run_type:
        description: 'Type of monitoring run'
        required: false
        default: 'full'
        type: choice
        options:
          - full
          - issues-only
          - performance-only

env:
  XCODE_VERSION: '15.0'

jobs:
  automated-monitoring:
    name: Automated Quality Monitoring
    runs-on: macos-latest
    timeout-minutes: 20
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for performance trends

      - name: Setup Xcode
        uses: maxim-lobanov/setup-xcode@v1
        with:
          xcode-version: ${{ env.XCODE_VERSION }}

      - name: Make Automation Scripts Executable
        run: |
          chmod +x Tools/Automation/detect_issues.sh
          chmod +x Tools/Automation/monitor_performance.sh
          chmod +x Tools/Automation/run_parallel_tests.sh

      - name: Run Issue Detection
        if: github.event.inputs.run_type != 'performance-only'
        run: |
          echo "ðŸ” Running automated issue detection..."
          Tools/Automation/detect_issues.sh
        continue-on-error: true

      - name: Run Performance Monitoring
        if: github.event.inputs.run_type != 'issues-only'
        run: |
          echo "ðŸ“Š Running performance regression monitoring..."
          Tools/Automation/monitor_performance.sh
        continue-on-error: true

      - name: Generate Monitoring Report
        run: |
          echo "# Automated Quality Monitoring Report" > monitoring-report.md
          echo "" >> monitoring-report.md
          echo "**Date**: $(date -u +'%Y-%m-%d %H:%M:%S UTC')" >> monitoring-report.md
          echo "**Run Type**: ${{ github.event.inputs.run_type || 'scheduled' }}" >> monitoring-report.md
          echo "**Commit**: ${{ github.sha }}" >> monitoring-report.md
          echo "" >> monitoring-report.md

          # Count issues
          if [ -d "test_results/issues" ]; then
            ISSUE_COUNT=$(find test_results/issues -name "*.json" | wc -l)
            HIGH_ISSUES=$(find test_results/issues -name "*.json" -exec jq -r '.severity' {} \; 2>/dev/null | grep -c "high" || echo "0")
            MEDIUM_ISSUES=$(find test_results/issues -name "*.json" -exec jq -r '.severity' {} \; 2>/dev/null | grep -c "medium" || echo "0")

            echo "## Issues Summary" >> monitoring-report.md
            echo "- Total Issues: $ISSUE_COUNT" >> monitoring-report.md
            echo "- High Severity: $HIGH_ISSUES" >> monitoring-report.md
            echo "- Medium Severity: $MEDIUM_ISSUES" >> monitoring-report.md
            echo "" >> monitoring-report.md
          fi

          # Performance summary
          if [ -d "performance_history" ]; then
            TREND_FILES=$(find performance_history -name "*_trend_*.json" | wc -l)
            REGRESSIONS=$(find performance_history -name "*_trend_*.json" -exec jq -r '.regression_detected' {} \; 2>/dev/null | grep -c "true" || echo "0")

            echo "## Performance Summary" >> monitoring-report.md
            echo "- Trend Analyses: $TREND_FILES" >> monitoring-report.md
            echo "- Regressions Detected: $REGRESSIONS" >> monitoring-report.md
            echo "" >> monitoring-report.md
          fi

          # Recommendations
          echo "## Recommendations" >> monitoring-report.md
          if [ "$ISSUE_COUNT" -gt 0 ]; then
            echo "- Review detected issues in test_results/issues/" >> monitoring-report.md
          fi
          if [ "$REGRESSIONS" -gt 0 ]; then
            echo "- Address performance regressions in performance_history/" >> monitoring-report.md
          fi
          if [ "$ISSUE_COUNT" -eq 0 ] && [ "$REGRESSIONS" -eq 0 ]; then
            echo "- âœ… All quality metrics within acceptable ranges" >> monitoring-report.md
          fi

          cat monitoring-report.md

      - name: Upload Monitoring Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: automated-monitoring-results
          path: |
            test_results/
            performance_history/
            monitoring-report.md
          retention-days: 30

      - name: Create Issue on Critical Problems
        if: always()
        run: |
          # Check for critical issues that need immediate attention
          HIGH_ISSUES=$(find test_results/issues -name "*.json" -exec jq -r '.severity' {} \; 2>/dev/null | grep -c "high" || echo "0")
          REGRESSIONS=$(find performance_history -name "*_trend_*.json" -exec jq -r '.regression_detected' {} \; 2>/dev/null | grep -c "true" || echo "0")

          if [ "$HIGH_ISSUES" -gt 0 ] || [ "$REGRESSIONS" -gt 0 ]; then
            echo "ðŸš¨ Critical quality issues detected - creating tracking issue"

            # Create a summary for the issue
            SUMMARY="Automated Quality Monitoring: Critical Issues Detected

**High Severity Issues**: $HIGH_ISSUES
**Performance Regressions**: $REGRESSIONS
**Date**: $(date -u +'%Y-%m-%d %H:%M:%S UTC')
**Run**: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}

## Details
- Review monitoring artifacts for complete details
- Issues: test_results/issues/
- Performance: performance_history/

## Next Steps
1. Review high-severity issues immediately
2. Address performance regressions
3. Update quality gates if needed"

            # Note: In a real implementation, you would use the GitHub CLI or API to create an issue
            echo "$SUMMARY" > critical-issues-summary.txt
          else
            echo "âœ… No critical quality issues detected"
          fi

      - name: Final Status
        run: |
          echo "âœ… Automated quality monitoring completed"
          echo "Results available in monitoring artifacts"